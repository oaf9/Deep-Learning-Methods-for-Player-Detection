{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions for cropping images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_bottom(image, percent):\n",
    "    height, width = image.shape[:2]\n",
    "    cutoff = int(height * (1 - percent))\n",
    "    cropped_image = image[:cutoff, :]\n",
    "    return cropped_image\n",
    "\n",
    "def crop_top(image, percent):\n",
    "    height, width = image.shape[:2]\n",
    "    cutoff = int(height * percent)\n",
    "    cropped_image = image[cutoff:, :]\n",
    "    return cropped_image\n",
    "\n",
    "def crop_lr(image, percent):\n",
    "    height, width = image.shape[:2]\n",
    "    crop_width = int(width * percent)\n",
    "    cropped_image = image[:, crop_width:-crop_width]\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Main PaddleOCR Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block loops over the SoccerNet challenge tracklets and makes predictions for each image. Make sure the path to the data is correct for your computer. The predictions for the tracklet are stored in the 'jersey' array if they surpass the confidence threshold (otherwise they're assigned -1). A majority vote is used to determine the overall prediction for the tracklet. There are some image processing steps prior to PaddleOCR detection/recognition: cropping, rescaling, gaussian blur, grayscale, contrast. The tracklet folder indices and their corresponding labels are stored in the 'folder' and 'predictions' arrays, respectively. Note: you may encounter an indexing error for extracting the prediction tuple (I didn't have this issue but someone on my team did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from paddleocr import PaddleOCR\n",
    "from collections import Counter\n",
    "import cv2, os\n",
    "\n",
    "# Initialize PaddleOCR with the English language\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en', show_log=False)\n",
    "\n",
    "predictions = []\n",
    "folder = []\n",
    "\n",
    "# Loop over all 1425 challenge tracklets\n",
    "for i in range(0,1426):\n",
    "\n",
    "    # Path to the folder containing images\n",
    "    folder_path = f'/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/SoccerNet/jersey-2023/challenge/images/{i}/'\n",
    "\n",
    "    # Get a list of all files in the folder\n",
    "    image_files = os.listdir(folder_path)\n",
    "\n",
    "    jersey_numbers = []\n",
    "\n",
    "    # Iterate over each image file in the folder\n",
    "    for file_name in image_files:\n",
    "        # Construct the full path to the image file\n",
    "        image_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Read the image using OpenCV\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "\n",
    "        # Crop\n",
    "        img = crop_bottom(img, 0.5)\n",
    "        img = crop_top(img, 0.1)\n",
    "        img = crop_lr(img, 0.1)\n",
    "\n",
    "        height, width = img.shape[:2]\n",
    "\n",
    "        # Make sure image has non-zero dimension to prevent error\n",
    "        if height < 1 or width < 1:\n",
    "            continue\n",
    "\n",
    "        # Rescale the image by factor 'scale'\n",
    "        scale = 3.0\n",
    "        img = cv2.resize(img, (round(scale * width), round(scale * height)), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # Reduce noise with a Gaussian blur\n",
    "        img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "        # Convert to grayscale\n",
    "        #if len(img.shape) == 3:  # If image is color (has 3 channels)\n",
    "        #    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply contrast\n",
    "        #alpha = 2  # Contrast control\n",
    "        #beta = 0   # Brightness control\n",
    "        #img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "\n",
    "        \n",
    "        # Perform OCR on the image\n",
    "        result = ocr.ocr(img, cls=True)\n",
    "        \n",
    "        # Check if the list is empty\n",
    "        if result:\n",
    "            # Extract the tuple ('13', 0.9994895458221436)\n",
    "            result = result[0][1]\n",
    "            # Only count numeric results (exclude detected letters)\n",
    "            if result[0].isdigit():\n",
    "                # Confidence threshold is 0.6\n",
    "                if result[1] > 0.6:\n",
    "                    jersey_numbers.append(int(result[0]))\n",
    "\n",
    "    print(jersey_numbers)\n",
    "\n",
    "    # Count occurrences of each value\n",
    "    counts = Counter(jersey_numbers)\n",
    "\n",
    "    # Majority vote (most common detected value is the jersey number)\n",
    "    if counts:\n",
    "        most_common_value = counts.most_common(1)[0][0]\n",
    "    else:\n",
    "        most_common_value = -1\n",
    "\n",
    "    print('Folder:',str(i),'Jersey:',str(most_common_value))\n",
    "    predictions.append(most_common_value)\n",
    "    folder.append(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output results to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block writes the results to a JSON dictionary file in the same format as the provided JSON files for the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "# Zip arrays A and B to create a list of tuples\n",
    "key_value_pairs = zip(folder,predictions)\n",
    "\n",
    "# Convert the list of tuples into a dictionary\n",
    "json_dict = dict(key_value_pairs)\n",
    "\n",
    "# Write the dictionary to a JSON file\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json.dump(json_dict, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block allows you to compare your JSON to the ground truth JSON. This was useful for evaluating the performance of our model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_json_files(file1, file2):\n",
    "    with open(file1, 'r') as f1:\n",
    "        data1 = json.load(f1)\n",
    "\n",
    "    with open(file2, 'r') as f2:\n",
    "        data2 = json.load(f2)\n",
    "\n",
    "    total_pairs_b = len(data2)\n",
    "    matching_pairs = 0\n",
    "\n",
    "    for key, value in data2.items():\n",
    "        if key in data1 and data1[key] == value:\n",
    "            matching_pairs += 1\n",
    "\n",
    "    if total_pairs_b > 0:\n",
    "        similarity_percentage = (matching_pairs / total_pairs_b) * 100\n",
    "    else:\n",
    "        similarity_percentage = 0\n",
    "\n",
    "    return similarity_percentage\n",
    "\n",
    "# Usage\n",
    "file1 = \"test_gt.json\"\n",
    "file2 = \"output.json\"\n",
    "similarity_percentage = compare_json_files(file1, file2)\n",
    "print(\"Accuracy of the model (% of correct predictions):\\n\", similarity_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Evaluations with a Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This codeblock defines functions for plotting a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def extract_values(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return list(data.values())\n",
    "\n",
    "def plot_confusion_matrix(true_file, pred_file):\n",
    "    # Extract true values and predictions from JSON files\n",
    "    true_values = extract_values(true_file)\n",
    "    predictions = extract_values(pred_file)\n",
    "\n",
    "    #true_values = true_values[0:100]\n",
    "\n",
    "    # Get unique labels\n",
    "    labels = np.unique(true_values + predictions)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(true_values, predictions, labels=labels)\n",
    "\n",
    "    # Normalize confusion matrix\n",
    "    cm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 0.01)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=False, fmt=\".2f\", cmap=\"viridis\", xticklabels=labels, yticklabels=labels, linewidths=.5, linecolor='gray')\n",
    "    plt.xlabel('Predicted', fontsize=24)  # Adjust fontsize as needed\n",
    "    plt.ylabel('True', fontsize=24)       # Adjust fontsize as needed\n",
    "    plt.title('Normalized Confusion Matrix, batch size 32 (color)', fontsize=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block plots the confusion matrix for two JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_file = 'test_gt.json'\n",
    "pred_file = 'output.json'\n",
    "plot_confusion_matrix(true_file, pred_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Multipass Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multipass approach we used for our challenge submission was accomplished by running the main loop multiple times with different image processing parameters. Make sure to save all the JSON files for each pass. One could write a script to automatically use them to aggregate results as shown in Figure 7 of our report. We instead manually aggregated results in Excel. If you have further requests for code or explanations, or if you have issues running the code, please contact zcroft@umich.edu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
