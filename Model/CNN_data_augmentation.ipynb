{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OG8ulX8034Vu"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import json\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import zipfile\n",
        "\n",
        "\"\"\"\n",
        "This function will load the data and return two zipped arrays:\n",
        "\n",
        "output:       contains an image stored as a numpy array\n",
        "class_labels: contains the corresponding label for each element of output\n",
        "\n",
        "@params\n",
        "dir: should be the path that contains both train images, and json dic with labels\n",
        "save: If you want it to save the output as a zip file (so you don't have to do this twice)\n",
        "\"\"\"\n",
        "\n",
        "def load_data(dir, save = False):\n",
        "\n",
        "    #labels is a dictionary mapping file_numer ->class_label\n",
        "    with open(dir + \"/train_gt.json\") as file:\n",
        "        labels = json.load(file)\n",
        "\n",
        "    #converts an image to a numpy array\n",
        "\n",
        "    \"\"\"\n",
        "    Eventually we will want to resize the images when we localize. This is just so that they are all the same size.\n",
        "    \"\"\"\n",
        "    get_image = lambda file_name: cv2.resize(cv2.imread(file_name),(40, 100))\n",
        "\n",
        "    output = []\n",
        "    class_labels = []\n",
        "\n",
        "    #iterate through the folders, convert the images to RGB arrays, and then append the class label\n",
        "    for folder in list(os.listdir(dir+\"/images\")):\n",
        "\n",
        "        if folder == '.DS_Store': continue\n",
        "        #if (folder != '1' and folder != '2'): continue\n",
        "\n",
        "        cls = labels[folder]\n",
        "        images = os.listdir(os.path.join(dir+\"/images\", folder))\n",
        "\n",
        "        for image in images:\n",
        "            output.append(get_image(os.path.join(dir+\"/images\", folder, image)))\n",
        "            class_labels.append(cls)\n",
        "\n",
        "    zip_file = zip(output, class_labels)\n",
        "    if save:\n",
        "        np.savez_compressed(dir+\"/numpy_data.npz\", output, labels)\n",
        "\n",
        "    return zip_file\n",
        "\n",
        "def load_small_data(dir):\n",
        "\n",
        "    data = np.load(dir)\n",
        "    lst = data.files\n",
        "    X = data[lst[0]]\n",
        "    y = data[lst[1]]\n",
        "\n",
        "    return X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Dz1l0mfD4gVF"
      },
      "outputs": [],
      "source": [
        "X,y = load_small_data('/content/jersey_sample.npz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0PZV3jj4kzy"
      },
      "source": [
        "### **Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MqVEPKCH4oyq"
      },
      "outputs": [],
      "source": [
        "from keras import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, ZeroPadding2D\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "onF7hLxa4t4s"
      },
      "outputs": [],
      "source": [
        "# right now, there is no data processing.\n",
        "# But, We need to make sure that all the images have the same shape.\n",
        "# and one hot encode y labels\n",
        "def process_data(X_data, y_data):\n",
        "\n",
        "    \"\"\"\n",
        "    Prepare the response:\n",
        "\n",
        "    This part of the function just basically maps the classes to the set {0, ... 44}, and then one-hot encodes the response\n",
        "    \"\"\"\n",
        "    #for to_categorical to work, we need to map the labels to {0, ... 44}\n",
        "    label_to_int = {}\n",
        "    int_to_label = {}\n",
        "\n",
        "    for index, label in enumerate(np.unique(y_data)):\n",
        "        label_to_int[label]=index\n",
        "        int_to_label[index]=label\n",
        "\n",
        "\n",
        "    y_data_new = np.vectorize(label_to_int.__getitem__)(y_data)\n",
        "    y_data_new = to_categorical(y_data_new)\n",
        "\n",
        "    #X_train, y_train = zip(*load_data(directory, True))\n",
        "    X_data = np.array(X_data)\n",
        "\n",
        "\n",
        "    return X_data, y_data_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbgFKyPF4v4j",
        "outputId": "967a805f-fe6a-40d1-fff4-34d443f42d77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(36650, 45)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, y_train = process_data(X,y)\n",
        "\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX26bQK04xo2"
      },
      "source": [
        "### **Model with data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiJtfore45l-",
        "outputId": "cab59b93-2d8d-4252-82fe-6ed5f1abddf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 98, 38, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 98, 38, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 98, 38, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 49, 19, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 49, 19, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 47, 17, 64)        18496     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 47, 17, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 47, 17, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 23, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 23, 8, 64)         0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 21, 6, 128)        73856     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 21, 6, 128)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 21, 6, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 10, 3, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10, 3, 128)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3840)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1966592   \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 512)               2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 45)                23085     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2085869 (7.96 MB)\n",
            "Trainable params: 2084397 (7.95 MB)\n",
            "Non-trainable params: 1472 (5.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation\n",
        "data_generator = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=10,  # Random rotations\n",
        "    width_shift_range=0.1,  # Random horizontal shifts\n",
        "    height_shift_range=0.1,  # Random vertical shifts\n",
        "    zoom_range=0.1,  # Random zoom\n",
        "    horizontal_flip=True,  # Random horizontal flips\n",
        "    fill_mode='nearest'  # Strategy for filling in newly created pixels\n",
        ")\n",
        "\n",
        "###### TODO: change to gray scale\n",
        "###### INV\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (100, 40, 3)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# First convolutional block\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Second convolutional block\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Third convolutional block\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Fully connected block\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(45, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfL4IxKN5f-t",
        "outputId": "cee00680-d6b4-4f6d-8386-669e904d7c9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1146/1146 [==============================] - 424s 367ms/step - loss: 2.8094 - accuracy: 0.2627\n",
            "Epoch 2/20\n",
            "1146/1146 [==============================] - 416s 363ms/step - loss: 2.1378 - accuracy: 0.3642\n",
            "Epoch 3/20\n",
            "1146/1146 [==============================] - 411s 359ms/step - loss: 1.9024 - accuracy: 0.4249\n",
            "Epoch 4/20\n",
            "1146/1146 [==============================] - 425s 371ms/step - loss: 1.7497 - accuracy: 0.4662\n",
            "Epoch 5/20\n",
            "1146/1146 [==============================] - 416s 363ms/step - loss: 1.6450 - accuracy: 0.4938\n",
            "Epoch 6/20\n",
            "1146/1146 [==============================] - 436s 380ms/step - loss: 1.5670 - accuracy: 0.5169\n",
            "Epoch 7/20\n",
            "1146/1146 [==============================] - 435s 379ms/step - loss: 1.5049 - accuracy: 0.5317\n",
            "Epoch 8/20\n",
            "1146/1146 [==============================] - 454s 396ms/step - loss: 1.4445 - accuracy: 0.5510\n",
            "Epoch 9/20\n",
            "1146/1146 [==============================] - 439s 383ms/step - loss: 1.4106 - accuracy: 0.5603\n",
            "Epoch 10/20\n",
            "1146/1146 [==============================] - 437s 381ms/step - loss: 1.3774 - accuracy: 0.5663\n",
            "Epoch 11/20\n",
            "1146/1146 [==============================] - 432s 377ms/step - loss: 1.3405 - accuracy: 0.5767\n",
            "Epoch 12/20\n",
            "1146/1146 [==============================] - 424s 370ms/step - loss: 1.3190 - accuracy: 0.5865\n",
            "Epoch 13/20\n",
            "1146/1146 [==============================] - 415s 362ms/step - loss: 1.2864 - accuracy: 0.5950\n",
            "Epoch 14/20\n",
            "1146/1146 [==============================] - 437s 381ms/step - loss: 1.2646 - accuracy: 0.6000\n",
            "Epoch 15/20\n",
            "1146/1146 [==============================] - 418s 365ms/step - loss: 1.2342 - accuracy: 0.6083\n",
            "Epoch 16/20\n",
            "1146/1146 [==============================] - 432s 377ms/step - loss: 1.2218 - accuracy: 0.6120\n",
            "Epoch 17/20\n",
            "  94/1146 [=>............................] - ETA: 6:22 - loss: 1.1788 - accuracy: 0.6286"
          ]
        }
      ],
      "source": [
        "model.fit(data_generator.flow(X_train, y_train), epochs=20)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
